{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cdba564-aca1-43d7-8159-be3e1f344312",
   "metadata": {},
   "source": [
    "# Pytorch e imágenes de 3D\n",
    "\n",
    "Tradicionalmente uno puede aplicar diferentes procesos y funciones a imágenes en 2D. En Deep Learning, es\n",
    "habitual tratar de utilizar **segmentación de objectos**, y **detección de objectos**. En Pytorch existen varios\n",
    "tipos de herramientas para llevar a cabo estos procesos.\n",
    "\n",
    "Sin embargo, en los últimos años se han desarrollado varios tipos de modelos que se pueden utilizar para\n",
    "el análisis y modelaje de objetos en 3D.\n",
    "\n",
    "Por ejemplo existen las siguientes redes / arquitecturas para objetos en 3D:\n",
    "- Nube de puntos (Point clouds): [PointNet](http://stanford.edu/~rqi/pointnet), [DGCNN](https://liuziwei7.github.io/projects/DGCNN)\n",
    "- Redes de registro: [PointNetLK](https://github.com/hmgoforth/PointNetLK), [DCP](https://arxiv.org/abs/1905.03304)\n",
    "\n",
    ", entre otras más.\n",
    "\n",
    "Para más información, pueden ver el siguiente artículo: [https://medium.com/@nabil.madali/introduction-to-3d-deep-learning-740c199b100c](https://medium.com/@nabil.madali/introduction-to-3d-deep-learning-740c199b100c)\n",
    "\n",
    "\n",
    "## Representaciones de imágenes en 3D\n",
    "\n",
    "Objectos en 3D pueden ser representados en diferentes formas. La siguiente imagen muestra como un conejo\n",
    "puede ser visualizado en 3D de diferentes maneras:\n",
    "- a) Point cloud\n",
    "- b) Voxel Grid\n",
    "- c) Triangular Grid\n",
    "- d) multi-view representation\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/0*jXcPM_tkNY1_lk55.png\" alt=\"neural_network\" style=\"width: 700px;\" align=\"center\"/>\n",
    "\n",
    "- Nube de puntos (Point clouds):\n",
    "    - Es una colección de puntos en 3D, en el cual cada punto se puede representar con coordenadas de X, Y, y Z.\n",
    "    - Similarmente se pueden atribuir más características del punto como color (RGB) y vectores normales (nx, ny, nz).\n",
    "    - Esta es la forma original de la data para carros autónomos ([LIDAR](https://medium.com/swlh/lidar-the-eyes-of-an-autonomous-vehicle-82c6252d1101))\n",
    "   \n",
    "- Voxel grid:\n",
    "    - Derivado de la nube de puntos, el Voxel grid es como un pixel en 3D.\n",
    "- Mesh:\n",
    "    - Superficie que consiste de polígonos convexos con vertices que unen cada uno de los polígonos.\n",
    "    - Las nubes de puntos pueden derivadas de estas superficies.\n",
    "- Representación de varios ángulos:\n",
    "    - Esta forma de representación es una colección de imágenes de 2D del objeto en 3D.\n",
    "\n",
    "Esto muestra que existen varias formas de representar un objecto en 3D, y existen herramientas y paquetes\n",
    "para poder visualizarlas y estudiarlas.\n",
    "\n",
    "## Visualización de datos\n",
    "\n",
    "Para esta parte, veremos como visualizar unos objetos en 3D del model [ModelNet40](https://modelnet.cs.princeton.edu/)\n",
    "\n",
    "### Descargando la data\n",
    "Primero descargaremos la data y la descomprimiremos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2143a3-c4fa-41d1-85c7-f4da623c928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando los paquetes necesarios\n",
    "!python -m pip install -r https://raw.githubusercontent.com/vcalderon2009/2021_06_Deep_Learning_tutorial/master/pkg_requirements.txt -q\n",
    "\n",
    "# Importando los paquetes necesarios\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotly.offline.init_notebook_mode(connected=True)\n",
    "plotly.offline.iplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a72aacf-f982-43ee-84bf-8b3c4c846550",
   "metadata": {},
   "source": [
    "Ahora podemos descargar la data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda26b5d-5503-4cb1-8ee9-621e999cc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
    "!unzip -q ModelNet10.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa4617-e3d4-45b3-825a-1d8623d50773",
   "metadata": {},
   "source": [
    "Ahora extraemos la metadata del archivo y construimos un diccionarios con las clases de la data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071242b-53ac-4b7d-afaa-7d14e3fc0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el camino de los archivos\n",
    "path = Path(\"ModelNet10\")\n",
    "\n",
    "# Folder con la data\n",
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "# Y extraemos las etiquetas de las diferentes imágenes\n",
    "classes = {folder: ii for ii, folder in enumerate(folders)}\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96ab77-117b-4a12-9fa0-1a9195639e1c",
   "metadata": {},
   "source": [
    "El siguiente paso es crear utilidades para leer los archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee6603-cd57-4c42-850e-dafbf9db1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    \"\"\"\n",
    "    Función para leer archivos `.off`, los cuales tienen los vertices y \"caras\" de\n",
    "    cada uno de los objetos.\n",
    "    \"\"\"\n",
    "    if 'OFF' != file.readline().strip():\n",
    "        raise('Not a valid OFF header')\n",
    "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    \n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d48a1-f281-4018-b367-c21cecdcb920",
   "metadata": {},
   "source": [
    "Por ejemplo podemos leer uno de los archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a44de-86a8-41ae-a976-8b20d0c742f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ModelNet10/desk/train/desk_0107.off\", \"r\") as f:\n",
    "    verts, faces = read_off(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9d52a-5a5e-4022-a119-180d09137b8e",
   "metadata": {},
   "source": [
    "Cada vertice consiste en 3 diferentes arrays que representan los coordenadas de cada punto.\n",
    "Similarmente cada cara consiste de 3 arrays con indices de cada vértice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fa4db-19c0-4e2a-9694-fcd1a2c343ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para visualizar las imágines\n",
    "# Download data set from plotly repo\n",
    "def visualize_mesh_plotly(points_arr, faces_arr=None, color=\"lightpink\", opacity=0.5):\n",
    "    # Extrayendo coordenadas\n",
    "    x, y, z = points_arr.T\n",
    "    if faces_arr is not None:\n",
    "        i, j, k = faces_arr.T\n",
    "    else:\n",
    "        i = j = k = None\n",
    "    # Dibujando plot\n",
    "    fig = go.Figure(data=[go.Mesh3d(x=x, y=y, z=z, i=i, j=j, k=k, color=color, opacity=opacity)])\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=40, r=20, t=40, b=30),\n",
    "        paper_bgcolor=\"white\",\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3a5f0-7afd-47ac-97e0-78fd2514aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mesh_plotly(np.asarray(verts), faces_arr=np.asarray(faces))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c7794d-e6cc-4519-8441-a095691da846",
   "metadata": {},
   "source": [
    "Pero lo que queremos es convertirlo a una *nube de puntos*. Para ello definimos 2 funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824a28f-1a0d-4ae0-806d-66814140d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función que nos deja ver solamente los puntos del objeto\n",
    "def visualize_rotate(data):\n",
    "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
    "    frames=[]\n",
    "\n",
    "    def rotate_z(x, y, z, theta):\n",
    "        w = x+1j*y\n",
    "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
    "\n",
    "    for t in np.arange(0, 10.26, 0.1):\n",
    "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
    "    fig = go.Figure(data=data,\n",
    "                    layout=go.Layout(\n",
    "                        updatemenus=[dict(type='buttons',\n",
    "                                    showactive=False,\n",
    "                                    y=1,\n",
    "                                    x=0.8,\n",
    "                                    xanchor='left',\n",
    "                                    yanchor='bottom',\n",
    "                                    pad=dict(t=45, r=10),\n",
    "                                    buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
    "                                                                    transition=dict(duration=0),\n",
    "                                                                    fromcurrent=True,\n",
    "                                                                    mode='immediate'\n",
    "                                                                    )]\n",
    "                                                    )\n",
    "                                            ]\n",
    "                                    )\n",
    "                                ]\n",
    "                    ),\n",
    "                    frames=frames\n",
    "            )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def pcshow(xs,ys,zs):\n",
    "    data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
    "                                   mode='markers')]\n",
    "    fig = visualize_rotate(data)\n",
    "    fig.update_traces(marker=dict(size=2,\n",
    "                      line=dict(width=2,\n",
    "                      color='DarkSlateGrey')),\n",
    "                      selector=dict(mode='markers'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2fb26-7a53-48bb-8c77-e198681b3d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcshow(*np.asarray(verts).T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df67c8-188a-4fde-bc5e-21f495a734da",
   "metadata": {},
   "source": [
    "Esta es la representación de la imagenen como una **nube de puntos**. Una forma de modificar esta data es\n",
    "distribuyendo uniformente los puntos de esta nube. Por ello utilizamos una funcíon para hacer \"sampling\" de la data\n",
    "para crear una nueva nube de puntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c7266-c83e-463c-a32b-921b798641f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a = np.linalg.norm(pt1 - pt2)\n",
    "        side_b = np.linalg.norm(pt2 - pt3)\n",
    "        side_c = np.linalg.norm(pt3 - pt1)\n",
    "        s = 0.5 * ( side_a + side_b + side_c)\n",
    "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "        \n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces = mesh\n",
    "        verts = np.array(verts)\n",
    "        areas = np.zeros((len(faces)))\n",
    "\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
    "                                           verts[faces[i][1]],\n",
    "                                           verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces = (random.choices(faces, \n",
    "                                      weights=areas,\n",
    "                                      cum_weights=None,\n",
    "                                      k=self.output_size))\n",
    "        \n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                   verts[sampled_faces[i][1]],\n",
    "                                                   verts[sampled_faces[i][2]]))\n",
    "        \n",
    "        return sampled_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9a388-1b4f-4938-8ac1-b00420c47dc5",
   "metadata": {},
   "source": [
    "Digamos que queremos **3000 puntos** como nuestra nube de puntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff4efb-d05f-4be2-9ddf-57346a487993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos transformación\n",
    "pointcloud = PointSampler(3000)((verts, faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44284f92-c064-4683-888d-dd1ddec2ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Número original de puntos: '{0}'\".format(np.asarray(verts).shape[0]))\n",
    "print(\">>> Número nuevo de puntos: '{0}'\".format(pointcloud.shape[0]))\n",
    "\n",
    "# Pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484a5a6-83d1-406d-bdc5-5d9612751a27",
   "metadata": {},
   "source": [
    "Y podemos visualizar la nueva estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1095359-df2b-4a16-a0ff-478fdb6b6b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcshow(*pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79994a9-41e3-4292-af68-d3b8f2d9b88c",
   "metadata": {},
   "source": [
    "### Normalización de la data\n",
    "\n",
    "Uno de los métodos para *preparar* la data es normalizarla con respecto los valores.\n",
    "En este caso, queremos normalizar la data por el valor máximo y por el promedio de los valores. Esto\n",
    "es como poner a la imagen dentro de una esfera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476fe56-9355-4df3-b40c-072eca686829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return  norm_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386a97e-0860-4c74-92e0-ba3a1c50a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pointcloud = Normalize()(pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364c09f-a154-4983-b590-eb5d6d3b9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcshow(*norm_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922739d2-be62-4b89-8c55-47a4d2eb029f",
   "metadata": {},
   "source": [
    "### Aumentación de data\n",
    "\n",
    "Similar a 2D, uno puede *aumentar* la data al aplicar transformaciones a la data. En este caso rotaremos las nubes de puntos y\n",
    "agregaremos **ruido** a las nubes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f7e3e-40fa-4950-a1a5-839e46ca5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  rot_pointcloud\n",
    "    \n",
    "class RandomNoise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  noisy_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617f5ae-8818-484d-b78a-c2a8d7266928",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_pointcloud = RandRotation_z()(norm_pointcloud)\n",
    "noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efe79f-29cd-4489-b03a-230eaddde926",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcshow(*noisy_rot_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a21faa-6997-4fba-8520-5d2a4535ed09",
   "metadata": {},
   "source": [
    "### Otras utilidades\n",
    "\n",
    "En este caso, definiremos una función para las tranformaciones y para convertir un `numpy.ndarray` a un tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921af0f-4910-44ea-b9ad-c6688ee08cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        return torch.from_numpy(pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69602950-836b-403d-bdbf-42159bffa95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "                                PointSampler(1024),\n",
    "                                Normalize(),\n",
    "                                ToTensor()\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af277369-fdf4-4438-914b-e3ed05c4d768",
   "metadata": {},
   "source": [
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d3ca66-c057-455f-b18d-a3f5e77736b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_rot_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb157d-0813-4f1c-bf14-ce9dc5aa6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ToTensor()(noisy_rot_pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859b557-9e35-47ca-8977-2c97f8ebdac7",
   "metadata": {},
   "source": [
    "### Dataset y Dataloader\n",
    "\n",
    "Ya que hemos definido las funciones necesarias para aplicar a nuestra data, ahora tenemos\n",
    "que definir nuestra data para alimentar al modelo. Por ello, vamos a crear nuestra clase\n",
    "para las nubes de puntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5097a-eab6-4e4b-855f-c9c787beeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file):\n",
    "        verts, faces = read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms((verts, faces))\n",
    "        return pointcloud\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a2d229-e8bd-4ff8-a068-9d4f86d13b41",
   "metadata": {},
   "source": [
    "Definimos nuestra data de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ede14b-31f3-4297-9678-3c979d08d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                    PointSampler(1024),\n",
    "                    Normalize(),\n",
    "                    RandRotation_z(),\n",
    "                    RandomNoise(),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67453899-e185-466e-9d1a-761ba764008a",
   "metadata": {},
   "source": [
    "Y separamos la data entre \"entrenamiento\" y \"validación\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d9c95-0d64-4bfc-8951-d776c5569eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(path, transform=train_transforms)\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e87b02-e28a-4259-ad56-3985ca913a07",
   "metadata": {},
   "source": [
    "Para uso nuestor, creamos un diccionario que contiene los índices y nombres de cada una de las diferentes\n",
    "clases / etiquetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322a802-4918-4ef0-a3c7-67fa36a9e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_classes = {i: cat for cat, i in train_ds.classes.items()};\n",
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c46ae3-0dca-44db-85d6-2d7814909cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n",
    "print('Class: ', inv_classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176f272-8c1a-477f-bca0-bb8293d1d6a2",
   "metadata": {},
   "source": [
    "Y por último, definimos nuestro **DataLoader**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa9932-2ff4-4070-8342-a44ec1a4d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064d792-b114-42a6-b205-d1922221af69",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "El modelo que utilizaremos se llama **PointNet** y es un modelo que trata de clasificar\n",
    "nubes de puntos.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/700/1*6ovpVlWKU3ZKk2OT_WKZHA.png\" alt=\"neural_network\" style=\"width: 700px;\" align=\"center\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e4d3d-8708-42b5-86a9-22cd40812c07",
   "metadata": {},
   "source": [
    "Las siguientes funciones y clases definirán la arquitectura de **PointNet** y será este modelo el cuál usaremos\n",
    "para entrenar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eaa53c-72aa-4c18-b2da-3d1525b10fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "    \n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "    \n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6755d-8f12-4568-bbf7-c3eae3739f96",
   "metadata": {},
   "source": [
    "Por último, definiremos nuestra función de pérdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dae64b-3f53-4ba8-9aed-5f61b4e62553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1965327-034b-404e-9b7c-ed08a67c9b29",
   "metadata": {},
   "source": [
    "#### Entrenando el modelo\n",
    "\n",
    "El último paso es entrenar modelo con la data de `ModelNet40`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa683b5-0c38-44b3-bb44-055e4fffaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9fef37-8f62-4de2-9bd6-928976189b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo\n",
    "pointnet = PointNet()\n",
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1430e7-58f5-4313-a2af-682697d9cf7a",
   "metadata": {},
   "source": [
    "Definimos nuestro optimizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f77e0a-fc03-426f-b22d-dee649b341ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271b49d-59f3-42b7-ab30-a4df4ad9f8e9",
   "metadata": {},
   "source": [
    "Y escribimos nuestra función para que el modelo se entrene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cd32f-7d2a-4f60-9b20-d785469cedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            torch.save(pointnet.state_dict(), \"save_{0}.pth\".format(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc15b5b-e6e7-4029-9ee5-336e4a331d2f",
   "metadata": {},
   "source": [
    "Empezamos con el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa61185-e5eb-4572-9586-c48aa953b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(pointnet, train_loader, valid_loader,  save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c4dd2-ab47-4c60-9c48-cbf5b0d942e4",
   "metadata": {},
   "source": [
    "#### Test / Validación\n",
    "\n",
    "Por último queremos ver que tan bien se entrenó el modelo con la data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9312bbc-eae0-4a71-8226-7bcab35a73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d9050-8dfd-4f8d-be26-1eaff9d1db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNet()\n",
    "pointnet.load_state_dict(torch.load('save.pth'))\n",
    "pointnet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ab57b-fbf6-4edb-a13c-7aee851d82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(valid_loader):\n",
    "        print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
    "                   \n",
    "        inputs, labels = data['pointcloud'].float(), data['category']\n",
    "        outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        all_preds += list(preds.numpy())\n",
    "        all_labels += list(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c44dcf-390a-4789-9aaf-39024b8a5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds);\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b8faa-3332-4a00-916a-0570895a4404",
   "metadata": {},
   "source": [
    "Y ahora podemos visualizar los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63eb77-1a3f-473b-96f0-f936611f9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcbe20d-ec24-4cbe-af9e-73d9064711b4",
   "metadata": {},
   "source": [
    "Y ahora miremos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1b1f4-74d1-46a9-a1f2-7c44a7ade3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed2f66-5953-4e93-9b5b-9d9ea0c97d85",
   "metadata": {},
   "source": [
    "Y sin normalización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494f873-0372-497b-9409-c98b8541fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
