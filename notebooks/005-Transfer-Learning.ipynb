{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5206f4e6-fa41-4a23-b9b6-7172cd4d0b60",
   "metadata": {},
   "source": [
    "# Transfer learning en Pytorch\n",
    "\n",
    "El concepto de transfer learning es un método donde el modelo que ya fue entrenado para una\n",
    "aplicación es utilizado para otra aplicación. Por ejemplo, uno puede utilizar un modelo ya\n",
    "*pre-entrenado* como punto de partida para desarrollar un modelo para una segunda aplicación.\n",
    "\n",
    "En computer visión, esto es algo común que se utiliza y que ha demostrado una gran ventaja.\n",
    "\n",
    "## Transferir aprendizaje con datos de imágenes\n",
    "\n",
    "Es común realizar el aprendizaje por transferencia con problemas de modelado predictivo que utilizan datos de imagen como entrada.\n",
    "\n",
    "Esta puede ser una tarea de predicción que toma fotografías o datos de video como entrada.\n",
    "\n",
    "Para este tipo de problemas, es común utilizar un modelo de aprendizaje profundo previamente entrenado para una tarea de clasificación de\n",
    "imágenes grande y desafiante, como la competencia de clasificación de fotografías de la clase [ImageNet](https://www.image-net.org/) 1000.\n",
    "\n",
    "<img src=\"https://cv.gluon.ai/_images/imagenet_banner.jpeg\" alt=\"neural_network\" style=\"width: 700px;\" align=\"center\"/>\n",
    "\n",
    "Dentro de \"transfer learning\", se destacan varios modelos. Por ejemplo:\n",
    "- Modelo Oxford VGG\n",
    "- Modelo Microsoft ResNet\n",
    "\n",
    "Una de las razones por las que el \"transfer learning\" es llamativo es porque se puede utilizar\n",
    "cuando uno tiene un **número pequeño o limitado de data**. \n",
    "\n",
    "Si quieren ver más sobre otros modelos que se han hecho públicos y ya están entrenados, se pueden dirigir a [Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo) en Github.\n",
    "\n",
    "### Cómo funciona el transfer learning\n",
    "\n",
    "Uno puede pensar sobre \"transfer learning' como un problema de optimización, en donde se trata de\n",
    "optimizar las **últimas capas** del modelo y reentrenarlas para la aplicación de uno.\n",
    "\n",
    "1. Uno entrena un modelo con una gran cantidad de data.\n",
    "2. Ya que el modelo es entrenado, éste se puede utilizar para crear una aplicación bien general que se puede aplicar a varios problemas.\n",
    "3. Si uno quiere utilizar este modelo para algo especifico, uno entrena solamente la parte final de la red con la data que no tiene.\n",
    "\n",
    "La siguiente imagen representa el concept de \"transfer learning\" a más detalle:\n",
    "\n",
    "<img src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/Transfer-learning-idea.jpg?resize=768%2C432&ssl=1\" alt=\"neural_network\" style=\"width: 700px;\" align=\"center\"/>\n",
    "\n",
    "Más específico:\n",
    "\n",
    "<img src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/Transfer-learning-steps.png?w=921&ssl=1\" alt=\"neural_network\" style=\"width: 700px;\" align=\"center\"/>\n",
    "<img src=\"https://i0.wp.com/neptune.ai/wp-content/uploads/Transfer-learning-steps-2.png?w=850&ssl=1\" alt=\"neural_network\" style=\"width: 700px;\" align=\"center\"/>\n",
    "\n",
    "## Ejemplo de Transfer Learning\n",
    "\n",
    "En el siguiente tutorial, trataremos de clasificar imágenes de *abejas* y *hormigas*. Utilizaremos la data de 120\n",
    "imágenes por cada clase para entrenar el modelo, y luego validaremos los resultados con 75 imágenes de *abejas* y\n",
    "*hormigas*. El concepto de este tutorial fue adquirido de acá: [Link](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "\n",
    "### Descargando la data\n",
    "\n",
    "Lo primero que tendremos que hacer es descargar la data necesaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5011a4d-3715-4f96-ad37-72a5c01e71ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010caf41-5376-4123-80d3-b772dcfcb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data para transfer learning\n",
    "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip .\n",
    "    \n",
    "# Creando directorio donde se bajará la data:\n",
    "transfer_learning_directorio = Path(\".\").joinpath(\"transfer_learning_data\").resolve()\n",
    "transfer_learning_directorio.mkdir(exist_ok=True, parents=True)\n",
    "# extract it in the current folder\n",
    "!unzip hymenoptera_data.zip -d ./transfer_learning_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a60d8-7302-41d5-9435-86feba2fac78",
   "metadata": {},
   "source": [
    "### Normalización y transformación de la data\n",
    "\n",
    "El siguiente paso es preparar la data para que se pueda usar en el modelo pre-entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f2d72-04c1-4d67-bb4e-623d9f0afff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentación de data:\n",
    "# Un metodo para entrenar modelos de Deep Learning con imágenes es modificar la \"apariencia\" de\n",
    "# las imágenes que se utilizan para el entrenamiento. Por ejemplo, se acostumbra a\n",
    "# rotar las imágenes, normalizar los datos de la imágenes, etc. para que el modelo pueda\n",
    "# aprender más \"razgos\" de las imágenes y por ende desarrollar un mejor modelo.\n",
    "# \n",
    "# \n",
    "# Para las imágenes de validación, solamente normalizamos las imágenes.\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4851f-ce00-4334-8860-31a890e4a933",
   "metadata": {},
   "source": [
    "Estas transformaciónes son solamente para que las imágenes de entrenamiento\n",
    "y validación tengan las dimensiones correctas para el modelo.\n",
    "\n",
    "### Definición de los datasets\n",
    "\n",
    "El siguiente paso es la definición de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e7a89-7d2c-4635-af48-bf21d83b246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder en el cuál se encuentran los archivos\n",
    "data_dir = 'transfer_learning_data/hymenoptera_data'\n",
    "\n",
    "# Creamos un diccionario para el \"training\" y \"validation\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "# Creamos un \"DataLoader\", el cual nos dará las imágenes cada vez que las pidamos\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "# Extraemos los tamaños de los datasets\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "# Los nombres de las diferentes clases\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Por último, definimos el dispositivo sobre el cuál se ejecutará el entrenamiento\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a211819-9d6e-4fa5-8764-742546d81526",
   "metadata": {},
   "source": [
    "### Examinando la data\n",
    "\n",
    "Ya que hemos definido los diferentes datasets para el **entrenamiento** y la **validación**,\n",
    "podemos visualizar algunas de las imágnes como parte de nuestro EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a12803-4a6d-473d-af05-cfecaef5d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"\n",
    "    Función para visualizar las imágenes\n",
    "    \"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Agarramos un cierto número de datos y extraemos\n",
    "# las imágenes y sus respectivos etiquetas (\"labels\").\n",
    "# Esta es parte de la data de \"entrenamiento\"\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Creamos una figura con varias imágenes y las visualizamos\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf52e4-6e6a-45ef-98b0-ca4133170bd1",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo\n",
    "\n",
    "La siguiente parte vamos a entrenar el modelo con las imágenes que tenemos.\n",
    "Primero definiremos ciertas funciones que se usarán a lo largo del tutorial:\n",
    "\n",
    "#### Función de entrenamiento\n",
    "Esta función es la función principal para entrenar un modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428595b-d130-4adc-a8cf-a3cdf181f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \"\"\"\n",
    "    Función para entrenar un modelo.\n",
    "    \n",
    "    Parámetros\n",
    "    -------------\n",
    "    model :\n",
    "        Modelo que se utiliza y se está entrenando.\n",
    "    \n",
    "    criterion :\n",
    "        Criterio que se utiliza como el \"loss function\".\n",
    "    \n",
    "    optimizer :\n",
    "        Optimizador para modificar las pesas del modelo.\n",
    "    \n",
    "    scheduler :\n",
    "        Objeto que modifica la \"velocidad de aprendizaje\"\n",
    "        luego de un cierto número de épocas.\n",
    "    \n",
    "    num_epochs : int\n",
    "        Número total de épocas a utilizar para entrenar\n",
    "        el modelo.\n",
    "    \"\"\"\n",
    "    # Empieza el entrenamiento\n",
    "    since = time.time()\n",
    "    \n",
    "    # Copiando las pesas actuales del modelo\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # Inicializando el valor de la \"precisión\" (accuracy)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Es en este \"loop\" en donde empezamos a entrenar el modelo\n",
    "    # y el modelo empieza a aprender de la data dada.\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Cada época tiene 2 fases: entrenamiento y validación\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Hace que el modelo entre en modo de \"entrenamiento\"\n",
    "            else:\n",
    "                model.eval()   # Hace que el modelo entre en modo de \"validación\"\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Es en esta parte donde se aplica el\n",
    "                    # \"backpropagation\" y optimización de las pesas\n",
    "                    # NOTA: Esto solamente sucede durante el **entrenamiento**\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Recolectamos ciertas estadísticas del modelo\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Copiamos el modelo y lo preparamos para iniciar de nuevo\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Descargamos las pesas más óptimas del modelo\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b894c7-5e3e-4214-a51b-727451f9d7a7",
   "metadata": {},
   "source": [
    "La siguiente función es para visualizar los resultados del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc63a9-20ae-4d44-84bc-2817cdcc49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            # Este paso manda estos objectos al \"dispositivo\", i.e. \"cpu\" o \"gpu\".\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # En este paso el modelo crea predicciones\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9fc07-691f-4ca6-a8b5-e49e10cc1113",
   "metadata": {},
   "source": [
    "#### Mejorando el modelo pre-entrenado\n",
    "\n",
    "Es ahora en esta fase donde podemos utilizar un modelo que ya haya sido completamente\n",
    "entrenado con data similar a la que tenemos.\n",
    "\n",
    "Para este ejemplo, utilizaremos el modelo **ResNet18** y utilizaremos sus pesas al principio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff5193-e2cf-4b71-91ef-9dd054e58031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo y extraemos el número total de \"features\"\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# En esta parte se define el \"fully-connected\" layer, la cual se utilizará\n",
    "# para definir el número total de clases que queremos. En este caso,\n",
    "# estamos interesaos en ``2`` clases, y por ellos definimos **2** con parte\n",
    "# de la arquitectura del modelo.\n",
    "# \n",
    "# Esto se puede generalizar a ``nn.Linear(num_ftrs, len(class_names))``,\n",
    "# dependiendo del número total de clasificaciones que queremos.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "# Mandamos el objecto al dispositivo\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# En este caso decidimos el criterio / \"loss function\" de nuestro modelo.\n",
    "# Utilizaremos el ``CrossEntropyLoss`` que se utiliza frequentemente para\n",
    "# modelos de clasificación.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definimos el \"optimizador\" y miramos que todos los parámetros del modelo\n",
    "# sean optimizados.\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Finalmente podemos decidir un factor, por el cuál la \"velocidad de entrenamiento\"\n",
    "# se reducirá después de cierto número de épocas.\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af9723-7933-46fe-b3d7-1c5d2030e7ec",
   "metadata": {},
   "source": [
    "#### Entrenando y evaluando los modelos\n",
    "\n",
    "La última fase de entrenamiendo es ... entrenar el modelo. Uno puede definir si quiere entrenar\n",
    "este modelo en un **CPU** o un **GPU**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa8180-c306-4056-9c02-4907b14c9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501fb79-a446-4af0-ad9b-6c330821331b",
   "metadata": {},
   "source": [
    "Ahora podemos visualizar algunas de las predicciones del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9445cd45-9878-4afb-b9d7-76b36979ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd5f33-9024-45ca-9bce-cc497cd101af",
   "metadata": {},
   "source": [
    "#### Entranando de nuevo el modelo, pero con nuestra data.\n",
    "\n",
    "Ahora que ya hemos entrenado nuestro modelo con un modelo pre-entrenado, ahora podemos\n",
    "cambiar de estrategia y utilizar \"transfer learning\" para entrenar otro modelo con nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9f646-6a23-4d9c-bf28-124d0dbee457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a utilizar las pesas de este modelo y entrenarlo con nuestra data.\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Volvemos a definir la forma del \"fully-connected\" layer para que tengo una salida\n",
    "# de *2* clases.\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# Mandamos el objeto al \"CPU\" o \"GPU\"\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "# Loss function / Criterio\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# En este caso los parámetros de la \"última capa\" son optimizados.\n",
    "# En el ejemplo anterior, esto no fue así.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Finalmente podemos decidir un factor, por el cuál la \"velocidad de entrenamiento\"\n",
    "# se reducirá después de cierto número de épocas.\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d674637-dbf6-4456-98b5-7087c6e6e576",
   "metadata": {},
   "source": [
    "Una vez más entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e4318-c70f-4bf9-ad81-621622de55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db70c46-3539-411c-8d64-9d6891c56fcb",
   "metadata": {},
   "source": [
    "Y visualizamos los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0d5b0-056d-45c8-bb7e-0540d9344834",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0554ed-ae0e-45bd-b0e4-cc68f1a8116e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
